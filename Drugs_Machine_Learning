import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import math

import folium
import webbrowser
from folium import plugins
from folium.plugins import FastMarkerCluster
import plotly
import plotly.graph_objs as go

from sklearn import preprocessing
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import GridSearchCV

from xgboost import XGBClassifier
from xgboost import plot_importance
from xgboost import cv

from wordcloud import WordCloud
from collections import Counter
from PIL import Image

from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve
from sklearn.metrics import accuracy_score

import shap




df = pd.read_csv('../input/UCIdrug_train.csv')

test = pd.read_csv('../input/UCIdrug_test.csv')
df.head()
df.head()

data = pd.concat([df, test])
data.head()
data.describe()
data.info()
data.dtypes
data.isnull().any()
----This barplot shows the top 20 drugs with the 10/10 rating
--The is a bar graph which shows the top 20 drugs given in the data set with a rating of 10/10. 'Levonorgestrel' is the drug with the highest number of 10/10 ratings, about 1883 Ratings in the data set for 'Levonorgestrel

sns.set(font_scale = 1.2, style = 'darkgrid')
plt.rcParams['figure.figsize'] = [15, 8]

rating = dict(data.loc[data.rating == 10, "drugName"].value_counts())
drugname = list(rating.keys())
drug_rating = list(rating.values())

sns_rating = sns.barplot(x = drugname[0:20], y = drug_rating[0:20])

sns_rating.set_title('Top 20 drugs with 10/10 rating')
sns_rating.set_ylabel("Number of Ratings")
sns_rating.set_xlabel("Drug Names")
plt.setp(sns_rating.get_xticklabels(), rotation=90);



sns.set(font_scale = 1.2, style = 'darkgrid')
plt.rcParams['figure.figsize'] = [15, 8]

rating = dict(data.loc[data.rating == 1, "drugName"].value_counts())
drugname = list(rating.keys())
drug_rating = list(rating.values())

sns_rating = sns.barplot(x = drugname[0:20], y = drug_rating[0:20], palette = 'winter')

sns_rating.set_title('Top 20 drugs with 1/10 rating')
sns_rating.set_ylabel("Number of Ratings")
sns_rating.set_xlabel("Drug Names")
plt.setp(sns_rating.get_xticklabels(), rotation=90);


--The is a bar graph thatshows the top 20 drugs given in the data set with a rating of 1/10. 'Miconazole' is the drug with the highest number of 1/10 ratings, about 767

size = [68005, 46901, 36708, 25046, 12547, 10723, 8462, 6671]
colors = ['blue', 'red', 'maroon',  'magenta', 'orange', 'navy', 'lightgreen', 'yellow']
labels = "10", "1", "9", "8", "7", "5", "6", "4"

my_circle = plt.Circle((0, 0), 0.7, color = 'white')

plt.rcParams['figure.figsize'] = (10, 10)
plt.pie(size, colors = colors, labels = labels, autopct = '%.2f%%')
plt.axis('off')
plt.title('Pie Chart Representation of Ratings', fontsize = 25)
p = plt.gcf()
plt.gca().add_artist(my_circle)
plt.legend()
plt.show()
# A countplot of the ratings so we can see the distribution of ratings
plt.rcParams['figure.figsize'] = [20,8]
sns.set(font_scale = 1.4, style = 'whitegrid')
fig, ax = plt.subplots(1, 2)

sns_1 = sns.countplot(data['rating'], palette = 'spring', order = list(range(10, 0, -1)), ax = ax[0])
sns_2 = sns.distplot(data['rating'], ax = ax[1])
sns_1.set_title('Count of Ratings')
sns_1.set_xlabel("Rating")

sns_2.set_title('Distribution of Ratings')
sns_2.set_xlabel("Rating")


# This barplot show the top 10 conditions the people are suffering.
cond = dict(data['condition'].value_counts())
top_condition = list(cond.keys())[0:10]
values = list(cond.values())[0:10]
sns.set(style = 'darkgrid', font_scale = 1.3)
plt.rcParams['figure.figsize'] = [18, 7]

sns_ = sns.barplot(x = top_condition, y = values, palette = 'winter')
sns_.set_title("Top 10 conditions")
sns_.set_xlabel("Conditions")
sns_.set_ylabel("Count");

# Top 10 drugs which are used for the top condition, that is Birth Control
df1 = data[data['condition'] == 'Birth Control']['drugName'].value_counts()[0: 10]
sns.set(font_scale = 1.2, style = 'darkgrid')

sns_ = sns.barplot(x = df1.index, y = df1.values, palette = 'summer')
sns_.set_xlabel('Drug Names')
sns_.set_title("Top 10 Drugs used for Birth Control")
plt.setp(sns_.get_xticklabels(), rotation = 90);
# let's see the words cloud for the reviews 

# most popular drugs

from wordcloud import WordCloud
from wordcloud import STOPWORDS

stopwords = set(STOPWORDS)

wordcloud = WordCloud(background_color = 'lightblue', stopwords = stopwords, width = 1200, height = 800).generate(str(data['review']))

plt.rcParams['figure.figsize'] = (15, 15)
plt.title('WORD CLOUD OF REVIEWS', fontsize = 25)
print(wordcloud)
plt.axis('off')
plt.imshow(wordcloud)
plt.show()

# let's make a new column review sentiment 

data.loc[(data['rating'] >= 5), 'Review_Sentiment'] = 1
data.loc[(data['rating'] < 5), 'Review_Sentiment'] = 0

data['Review_Sentiment'].value_counts()


# a pie chart to represent the sentiments of the patients

size = [161491, 53572]
colors = ['lightblue', 'navy']
labels = "Positive Sentiment","Negative Sentiment"
explode = [0, 0.1]

plt.rcParams['figure.figsize'] = (10, 10)
plt.pie(size, colors = colors, labels = labels, explode = explode, autopct = '%.2f%%')
plt.axis('off')
plt.title('Pie Chart Representation of Sentiments', fontsize = 25)
plt.legend()
plt.show()

# VISUALIZATION OF USEFUL COUNT
# USEFUL COUNT dist plot

plt.rcParams['figure.figsize'] = (15, 8)
sns.distplot(data['usefulCount'], color = 'orange')
plt.title('The Distribution of Useful Counts', fontsize = 30)
plt.xlabel('Range of Useful Counts', fontsize = 15)
plt.ylabel('No. of Useful Counts', fontsize = 15)
plt.show()



######Machine Learning - Predecting rating based on review 

import numpy as np # linear algebra
import pandas as pd # data processing
import os
import matplotlib.pyplot as plt
import tqdm
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from gensim.models import Word2Vec 
from gensim.models.doc2vec import TaggedDocument
from gensim.models import Doc2Vec
from sklearn.naive_bayes import GaussianNB
import re
import spacy
from sklearn.utils import shuffle

from keras.utils.np_utils import to_categorical  
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif
from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.metrics import precision_score, confusion_matrix, recall_score
from sklearn.metrics import classification_report

from xgboost import XGBClassifier
import keras
drugsComTrain_raw = pd.read_csv('../input/UCIdrug_train.csv')
drugsComTest_raw = pd.read_csv('../input/UCIdrug_test.csv')
drugsComTrain_raw.shape
drugsComTrain_raw.rating.value_counts()
# CLUSTERING INTO 6 CATEGORIES

d = {1: 1, 
     2: 2, 3:2, 
     4: 3, 5: 3,
     6: 4, 7: 4,
     8: 5, 9: 5,
     10: 6}

drugsComTrain_raw['new_ratings'] = drugsComTrain_raw.rating.map(d)
drugsComTest_raw['new_ratings'] = drugsComTest_raw.rating.map(d)


# I do not remove stop words for this case
'not' in set(stopwords.words('english'))

all_reviews = []
for item in drugsComTrain_raw.review:
    temp = item
    temp = temp.lower()
    cleanr = re.compile('<.*?>')
    temp = re.sub(cleanr, ' ', temp)
    temp = re.sub(r'[?|!|\'|"|#]',r'',temp)
    temp = re.sub(r'[.|,|)|(|\|/]',r'',temp) 
#     temp = [word for word in temp.split(' ') if word not in set(stopwords.words('english'))]
    all_reviews.append(temp)
    
all_reviews_test = []
for item in drugsComTest_raw.review:
    temp = item
    temp = temp.lower()
    cleanr = re.compile('<.*?>')
    temp = re.sub(cleanr, ' ', temp)
    temp = re.sub(r'[?|!|\'|"|#]',r'',temp)
    temp = re.sub(r'[.|,|)|(|\|/]',r'',temp) 
#     temp = [word for word in temp.split(' ') if word not in set(stopwords.words('english'))]
    all_reviews_test.append(temp)


X = all_reviews
Y = drugsComTrain_raw.new_ratings
x_train, x_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.2, random_state=42)

x_test = all_reviews_test
y_test = drugsComTest_raw.new_ratings

# Use tfidf
vectorizer = TfidfVectorizer(ngram_range=(1,2))

x_train_vectors = vectorizer.fit_transform(x_train)
x_valid_vectors = vectorizer.transform(x_valid)
x_test_vectors = vectorizer.transform(x_test)

selector = SelectKBest(f_classif, k=min(1000, x_train_vectors.shape[1]))
selector.fit(x_train_vectors, y_train)
x_train_vectors = selector.transform(x_train_vectors).astype('float32')

x_valid_vectors = selector.transform(x_valid_vectors).astype('float32')
x_test_vectors = selector.transform(x_test_vectors).astype('float32')


x_train_vectors.shape, y_train.shape
round(drugsComTrain_raw.new_ratings.value_counts() * 10 / drugsComTrain_raw.shape[0])

#oversampling after tfidf

vectorizer = TfidfVectorizer(ngram_range=(1,2))

x_train_vectors = vectorizer.fit_transform(x_train)
x_valid_vectors = vectorizer.transform(x_valid)
x_test_vectors = vectorizer.transform(x_test)

selector = SelectKBest(f_classif, k=min(1000, x_train_vectors.shape[1]))
selector.fit(x_train_vectors, y_train)
x_train_vectors = selector.transform(x_train_vectors).astype('float32')

x_valid_vectors = selector.transform(x_valid_vectors).astype('float32')
x_test_vectors = selector.transform(x_test_vectors).astype('float32')

few_classes = list(map(lambda x: x in list(range(2, 6)), y_train.tolist()))
more_classes = list(map(lambda x: x in [1, 6], y_train.tolist()))
np.sum(few_classes)
##
few_classes = np.array(few_classes)
more_classes = np.array(more_classes)

x_train_few = x_train_vectors[few_classes]
y_train_few = y_train[few_classes]

x_train_more = x_train_vectors[more_classes]
y_train_more = y_train[more_classes]

##
all_x_train = list(x_train_few)
all_y_train = list(y_train_few)

for i in range(2):
    all_x_train.extend(x_train_few)
    all_y_train.extend(y_train_few)
    
all_x_train.extend(x_train_more)
all_y_train.extend(y_train_more)

all_x_train = np.concatenate([x_train_more.toarray(), x_train_few.toarray(), x_train_few.toarray(), x_train_few.toarray()], axis=0)
all_y_train = np.concatenate([y_train_more, y_train_few, y_train_few, y_train_few], axis=0)

new_x_train, new_y_train = shuffle(all_x_train, all_y_train)

##Selecting the model

#1 ExtraTreesClassifier


clf = ExtraTreesClassifier(n_estimators=100, random_state=0, class_weight='balanced')
clf.fit(x_train_vectors, y_train)
print('Accuracy of classifier on training set: {:.2f}'.format(clf.score(x_train_vectors, y_train) * 100))
print('Accuracy of classifier on test set: {:.2f}'.format(clf.score(x_test_vectors, y_test) * 100))
y_pred = clf.predict(x_test_vectors)
precision_score(y_test, y_pred, average='macro')
precision_score(y_test, y_pred, average='micro')
recall_score(y_test, y_pred, average='macro')
recall_score(y_test, y_pred, average='micro')
classification_report(y_test, y_pred2, target_names=["class 1", "class 2", "class 3", "class 4", "class 5", "class 6"])
cm = confusion_matrix(y_pred=y_pred, y_true=y_test)
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('ExtraTreesClassifier')
plt.colorbar()
tick_marks = np.arange(1, 11)
plt.xticks(tick_marks, np.arange(1, 11))
plt.yticks(tick_marks, np.arange(1, 11))
np.sum(y_pred == y_test) / len(y_test)

#MLP

import matplotlib.pyplot as plt
    import numpy as np
    import itertools

    accuracy = np.trace(cm) / float(np.sum(cm))
    misclass = 1 - accuracy

    if cmap is None:
        cmap = plt.get_cmap('Blues')

    plt.figure(figsize=(8, 6))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()

    if target_names is not None:
        tick_marks = np.arange(len(target_names))
        plt.xticks(tick_marks, target_names, rotation=45)
        plt.yticks(tick_marks, target_names)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]


    thresh = cm.max() / 1.5 if normalize else cm.max() / 2
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        if normalize:
            plt.text(j, i, "{:0.4f}".format(cm[i, j]),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")
        else:
            plt.text(j, i, "{:,}".format(cm[i, j]),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")


    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))
    plt.show()

model_mlp = keras.models.Sequential()

model_mlp.add(keras.layers.Dense(200, input_shape=(1000,)))
model_mlp.add(keras.layers.BatchNormalization())
model_mlp.add(keras.layers.Activation('relu'))
model_mlp.add(keras.layers.Dropout(0.5))

model_mlp.add(keras.layers.Dense(300))
model_mlp.add(keras.layers.BatchNormalization())
model_mlp.add(keras.layers.Activation('relu'))
model_mlp.add(keras.layers.Dropout(0.5))

model_mlp.add(keras.layers.Dense(100, activation='relu'))
model_mlp.add(keras.layers.Dense(7, activation='sigmoid'))

model_mlp.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

model_mlp.summary()

y_train_one_hot = to_categorical(new_y_train)
y_valid_one_hot = to_categorical(y_valid)
y_test_one_hot = to_categorical(y_test)
reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,
                              patience=3, min_lr=0.00001)
history = model_mlp.fit(new_x_train, y_train_one_hot, epochs=25, batch_size=64, validation_data=(x_valid_vectors, y_valid_one_hot), callbacks=[reduce_lr])

plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'valid'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'valid'], loc='upper left')
plt.show()
y_pred2 = model_mlp.predict_classes(x_test_vectors)
classification_report(y_test, y_pred2, target_names=["class 1", "class 2", "class 3", "class 4", "class 5", "class 6"])
cm2 = confusion_matrix(y_pred=y_pred2, y_true=y_test)
plot_confusion_matrix(cm           = cm2, 
                      normalize    = False,
                      target_names = ["class 1", "class 2", "class 3", "class 4", "class 5", "class 6"],
                      title        = "Confusion Matrix")

print('Accuracy = {}'.format(np.sum(y_pred2 == y_test) / len(y_test)))

#After decrease the dropout value


model_mlp2 = keras.models.Sequential()

model_mlp2.add(keras.layers.Dense(200, input_shape=(1000,)))
model_mlp2.add(keras.layers.BatchNormalization())
model_mlp2.add(keras.layers.Activation('relu'))
model_mlp2.add(keras.layers.Dropout(0.2))

model_mlp2.add(keras.layers.Dense(300))
model_mlp2.add(keras.layers.BatchNormalization())
model_mlp2.add(keras.layers.Activation('relu'))
model_mlp2.add(keras.layers.Dropout(0.2))

model_mlp2.add(keras.layers.Dense(100, activation='relu'))
model_mlp2.add(keras.layers.Dense(7, activation='sigmoid'))

model_mlp2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

reduce_lr2 = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,
                              patience=3, min_lr=0.00001)
history2 = model_mlp2.fit(new_x_train, y_train_one_hot, epochs=25, batch_size=64, validation_data=(x_valid_vectors, y_valid_one_hot), callbacks=[reduce_lr2])


plt.plot(history2.history['acc'])
plt.plot(history2.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'valid'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history2.history['loss'])
plt.plot(history2.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'valid'], loc='upper left')
plt.show()

y_pred2_2 = model_mlp2.predict_classes(x_test_vectors)
classification_report(y_test, y_pred2_2, target_names=["class 1", "class 2", "class 3", "class 4", "class 5", "class 6"])
cm2_2 = confusion_matrix(y_pred=y_pred2_2, y_true=y_test)

plot_confusion_matrix(cm           = cm2_2, 
                      normalize    = False,
                      target_names = ["class 1", "class 2", "class 3", "class 4", "class 5", "class 6"],
                      title        = "Confusion Matrix")

print('Accuracy = {}'.format(np.sum(y_pred2_2 == y_test) / len(y_test)))

# Zero drop out value



model_mlp3 = keras.models.Sequential()

model_mlp3.add(keras.layers.Dense(200, input_shape=(1000,)))
model_mlp3.add(keras.layers.Activation('relu'))

model_mlp3.add(keras.layers.Dense(300))
model_mlp3.add(keras.layers.Activation('relu'))

model_mlp3.add(keras.layers.Dense(100, activation='relu'))
model_mlp3.add(keras.layers.Dense(7, activation='sigmoid'))

model_mlp3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

history3 = model_mlp3.fit(new_x_train, y_train_one_hot, epochs=25, batch_size=64, validation_data=(x_valid_vectors, y_valid_one_hot))

plt.plot(history3.history['acc'])
plt.plot(history3.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'valid'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history3.history['loss'])
plt.plot(history3.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'valid'], loc='upper left')
plt.show()
y_pred2_3 = model_mlp3.predict_classes(x_test_vectors)
classification_report(y_test, y_pred2_3, target_names=["class 1", "class 2", "class 3", "class 4", "class 5", "class 6"])

cm2_3 = confusion_matrix(y_pred=y_pred2_3, y_true=y_test)

plot_confusion_matrix(cm           = cm2_3, 
                      normalize    = False,
                      target_names = ["class 1", "class 2", "class 3", "class 4", "class 5", "class 6"],
                      title        = "Confusion Matrix")

print('Accuracy = {}'.format(np.sum(y_pred2_3 == y_test) / len(y_test)))

